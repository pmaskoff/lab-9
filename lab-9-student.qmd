---
title: "Lab 9: Data Simulation Exploration"
author: "Parker Mascott"
date: "11/23/2024"
format: html
editor: source
embed-resources: true
code-tools: true
code-fold: true
execute:
  echo: true
  error: true
---

```{r}
#| label: setup
#| message: false
#| results: false
library(tidyverse)
library(knitr)
library(gt)
```

## Random Babies Simulation

Perhaps you have seen the [Random Babies applet](https://www.rossmanchance.com/applets/2021/randombabies/RandomBabies.html)? 
Suppose one night at a hospital four babies are born. The hospital is not very
organized and looses track of which baby belongs to each parent(s), so they 
decide to return the babies to parents at random. Here, we are interested in the
number of babies that are correctly returned to their respective parent(s).

**1. Simulate the distribution of the number of babies that are correctly returned. Use 10,000 simulations.**

::: callout-tip
Write a function to accomplish one simulation, then use `map_int()` to run
10,000 simulations. 

Keep in mind that your function needs to output a single number (not data frame) 
for it to be compatible with `map_int()`!
:::

```{r}
#| label: function-simulation-for-random-babies



randomBabies <- function(nBabies){
  samplebabes <- sample(1:nBabies, size = nBabies, replace = FALSE)
  correct <- sum(samplebabes == 1:nBabies)
  return(correct)
}

results <- map_int(.x = 1:10000,
                   .f = ~ randomBabies(n = 4)
                   )
```

**2. Create a table displaying the proportion of simulations where 0, 1, 2, 3, and 4 babies were given to their correct parent(s).** Hint: A `pivot_wider()` will be helpful here!

::: callout-tip
The output of your `map_int()` is a vector, but to make a nice table (and plot) 
you need this to be a data frame! Luckily, the `enframe()` function does just 
that--it converts a vector to a data frame. 

You may find the following code helpful:

```{r}
#| eval: false

enframe(results, 
        name = "simulation_number", 
        value = "ncorrect")
```
:::

```{r}
#| label: table-for-random-babies

enframed <- enframe(results, 
                      name = "simulation_number", 
                      value = "ncorrect")

proportions <- enframed |>
  count(ncorrect) |>
  mutate(proportion = n / sum(n)) |>
  select(ncorrect, proportion) |>
  pivot_wider(names_from = ncorrect, 
              values_from = proportion, 
              names_prefix = "ncorrect_")


proportions |>
  gt() |>
    tab_header(
    title = "Proportion of Simulations by Number of Correctly Returned Babies",
    subtitle = "Based on 10,000 simulations"
  ) |>
  cols_label(
    ncorrect_0 = "0 Correct",
    ncorrect_1 = "1 Correct",
    ncorrect_2 = "2 Correct",
    ncorrect_4 = "4 Correct"
  ) |>
  cols_align(
    align = "center",
    columns = everything()
  )
```

**3. Now create a barplot showing the proportion of simulations where 0, 1, 2, 3, and 4 babies were given to their correct parent(s).** 

::: callout-tip
You may find the following code helpful:

```{r}
#| eval: false

geom_bar(mapping = aes(y = after_stat(count) / sum(after_stat(count))
                       )
         )
```
:::

```{r}
#| label: visualization-for-random-babies

ggplot(enframed, 
       aes(x = factor(ncorrect)
           )) +
  geom_bar(mapping = aes(y = after_stat(count) / sum(after_stat(count))
                       )
         ) +
  labs(title = "Proportion of Correctly Returned Babies",
       x = "Number of Correctly Returned Babies",
       y = "",
       subtitle = "Proportion") +
  theme_minimal()

```

## Central Limit Theorem -- Optional & Somewhat Spicy

You have encountered the Central Limit Theorem in your previous statistics 
classes, whether or not is has been explicitly discussed. The Central Limit 
Theorem states that: 

> The sampling distribution of the mean will always be normally distributed, as
> long as the sample size is large enough, regardless of the underlying 
> distribution of the population. 

Remember back to your first statistics class when you had to check if the 
sample size was larger than 30 when testing if groups had different means? 
That's because of the Central Limit Theorem! Under certain conditions 
(e.g., sample size) the Central Limit Theorem ensures that the distribution 
of sample means will be approximately Normal, regardless of how skewed the 
underlying distribution of the population may be. 

A fundamental misunderstanding of the Central Limit Theorem is that it states 
that as a sample size gets larger, the population will be normally distributed. 
This is not the case, so let's do some exploring!  

**4. Write a function that simulates a specified number of sample means, for samples of size 100 drawn from a Chi-Squared distribution. Your function should allow the user to input:**

- **the number of means to simulate**
- **the degrees of freedom of the Chi-Squared distribution used to simulate data** 

I've provided some skeleton code to get you started. :) 

```{r}
simulate_means <- function(n, df){
  map_dbl(.x = 1:n, 
          .f = ~rchisq(n = 100, df) %>% mean()
          )
}
```

**5. Next, let's use the `crossing()` function to make a grid with inputs we want to pass into the `simulate_means()` function. Specifically, we want to explore the following values:**

-  **`n` = 10, 100, 1000, 10000**
-  **`df` = 10**

```{r}
grid <- crossing(n = c(10, 100, 1000, 10000), 
                 df = 10)
```

**6. Now, use a `p_map()` to create a new column of simulated means (using the `simulate_means()` function), for every value in your `grid`.**

::: {.callout-tip}
You will want to use the `unnest()` function to extract the results of the
`p_map()` (stored in the `simulated_means` column). 
:::

```{r}
all_simulations <- grid |> 
  mutate(simulated_means = pmap(.l = list(n, df), 
                                .f = simulate_means)
         ) |> 
  unnest(cols = simulated_means) 

```

**7. Create a table of the means from each of the simulations (10, 100, 1000, and 10000).** 

```{r}
#| label: table-of-simulated Means

r5 <- function(n) {
  rounded <- round(n, 5)
  return(rounded)
}

summaries <- all_simulations |> 
  group_by(n) |> 
  summarize(mean_sim_mean = r5(mean(simulated_means)),
            sd_sim_mean = r5(sd(simulated_means)),
            min_sim_mean = r5(min(simulated_means)),
            max_sim_mean = r5(max(simulated_means)),
            .groups = 'drop')

summaries |>
  gt() |>
    tab_header(
    title = "Means of Statistics Across Simulations",
    subtitle = "Including means of means, standard deviations, minimums, and maximums"
  ) |>
  cols_label(
    mean_sim_mean = "Mean",
    sd_sim_mean = "SD",
    min_sim_mean = "Minimum",
    max_sim_mean = "Maximum",
  ) |>
  cols_align(
    align = "center",
    columns = everything()
  )

summaries |>
  kable()

```

**8. Create a plot showing the distribution of simulated means from each of the simulations. Each simulation (10, 100, 1000, and 10000) should be its own facet!**
Hint: Make sure your facets have descriptive names! You might also want to free
the y-axis of the plots, since there are substantial differences in the sample
sizes between the simulations. 

**For extra pizzaz, add a vertical line for true mean (for a Chi-Square the mean is the degrees of freedom).**

```{r}
#| label: plot-of-simulated Means

```

## Challenge 9

Instructions for the challenge can be found on the course website or through 
the link in Canvas! 

